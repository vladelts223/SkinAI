import gradio as gr
import torch
import torch.nn.functional as F
from torchvision import transforms
import timm
import numpy as np
import cv2

MODEL_PATH = "model/fitzpatrick_vit_small_best.pth"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
CLASS_NAMES = ["Fitzpatrick I", "Fitzpatrick II", "Fitzpatrick III", "Fitzpatrick IV", "Fitzpatrick V",
               "Fitzpatrick VI"]


def load_model():
    model = timm.create_model("vit_small_patch16_224", pretrained=False, num_classes=6)
    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
    model.to(DEVICE).eval()
    return model


model = load_model()

captured_features = None


def hook_fn(module, input, output):
    global captured_features
    captured_features = output.detach().cpu()


for name, module in model.named_modules():
    if name == "blocks.11":
        module.register_forward_hook(hook_fn)


def process_feature_map(image_pil, features):
    patches = features[0, 1:, :]
    importance = torch.mean(torch.abs(patches), dim=-1).numpy()
    size = int(np.sqrt(importance.shape[0]))
    attn_map = importance.reshape(size, size)
    attn_map = (attn_map - attn_map.min()) / (attn_map.max() - attn_map.min() + 1e-8)
    attn_map = cv2.resize(attn_map, (image_pil.width, image_pil.height))
    heatmap = cv2.applyColorMap(np.uint8(255 * attn_map), cv2.COLORMAP_JET)
    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)
    img_np = np.array(image_pil.convert("RGB"))
    return cv2.addWeighted(img_np, 0.6, heatmap, 0.4, 0)


transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

DESCRIPTIONS = {
    "Fitzpatrick I": "–î—É–∂–µ —Å–≤—ñ—Ç–ª–∞ —à–∫—ñ—Ä–∞. –ó–∞–≤–∂–¥–∏ –æ–±–≥–æ—Ä–∞—î, –Ω—ñ–∫–æ–ª–∏ –Ω–µ –∑–∞—Å–º–∞–≥–∞—î. –ù–∞–π–≤–∏—â–∏–π —Ä–∏–∑–∏–∫ —Ñ–æ—Ç–æ–ø–æ—à–∫–æ–¥–∂–µ–Ω—å.",
    "Fitzpatrick II": "–°–≤—ñ—Ç–ª–∞ —à–∫—ñ—Ä–∞. –õ–µ–≥–∫–æ –æ–±–≥–æ—Ä–∞—î, –∑–∞—Å–º–∞–≥–∞—î –º—ñ–Ω—ñ–º–∞–ª—å–Ω–æ. –í–∏—Å–æ–∫–∏–π —Ä–∏–∑–∏–∫.",
    "Fitzpatrick III": "–°–µ—Ä–µ–¥–Ω—ñ–π —Ç–∏–ø. –ü–æ–º—ñ—Ä–Ω–æ –æ–±–≥–æ—Ä–∞—î, –∑–∞—Å–º–∞–≥–∞—î –¥–æ —Å–≤—ñ—Ç–ª–æ-–∫–æ—Ä–∏—á–Ω–µ–≤–æ–≥–æ –∫–æ–ª—å–æ—Ä—É.",
    "Fitzpatrick IV": "–û–ª–∏–≤–∫–æ–≤–∞ –∞–±–æ —Å–≤—ñ—Ç–ª–æ-–∫–æ—Ä–∏—á–Ω–µ–≤–∞ —à–∫—ñ—Ä–∞. –†—ñ–¥–∫–æ –æ–±–≥–æ—Ä–∞—î, –¥–æ–±—Ä–µ –∑–∞—Å–º–∞–≥–∞—î.",
    "Fitzpatrick V": "–¢–µ–º–Ω–æ-–∫–æ—Ä–∏—á–Ω–µ–≤–∞ —à–∫—ñ—Ä–∞. –î—É–∂–µ —Ä—ñ–¥–∫–æ –æ–±–≥–æ—Ä–∞—î, –∑–∞—Å–º–∞–≥–∞—î —ñ–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ.",
    "Fitzpatrick VI": "–ß–æ—Ä–Ω–∞ —à–∫—ñ—Ä–∞. –ü—Ä–∞–∫—Ç–∏—á–Ω–æ –Ω—ñ–∫–æ–ª–∏ –Ω–µ –æ–±–≥–æ—Ä–∞—î. –ù–∞–π–Ω–∏–∂—á–∏–π —Ä–∏–∑–∏–∫ –æ–ø—ñ–∫—ñ–≤."
}


def predict(image):
    if image is None: return None, None, ""
    global captured_features
    captured_features = None

    img_tensor = transform(image.convert("RGB")).unsqueeze(0).to(DEVICE)
    with torch.no_grad():
        outputs = model(img_tensor)
        probs = F.softmax(outputs, dim=1)[0]

    confidences = {CLASS_NAMES[i]: float(probs[i]) for i in range(len(CLASS_NAMES))}

    top_class = CLASS_NAMES[torch.argmax(probs).item()]
    description = f"### ‚ÑπÔ∏è –ü—Ä–æ —Ü–µ–π —Ç–∏–ø:\n{DESCRIPTIONS[top_class]}"

    visual_result = process_feature_map(image, captured_features) if captured_features is not None else np.array(image)

    return confidences, visual_result, description


with gr.Blocks() as demo:
    gr.Markdown("# üß¨ Fitzpatrick Skin Type Detector")
    gr.Markdown("Vision Transformer –∞–Ω–∞–ª—ñ–∑—É—î —Ç–µ–∫—Å—Ç—É—Ä—É —Ç–∞ –∫–æ–ª—ñ—Ä —à–∫—ñ—Ä–∏ –¥–ª—è –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Ñ–æ—Ç–æ—Ç–∏–ø—É")

    with gr.Row():
        with gr.Column():
            image_input = gr.Image(type="pil", label="–§–æ—Ç–æ —à–∫—ñ—Ä–∏")
            analyze_btn = gr.Button("üîç –ê–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏", variant="primary")
            desc_output = gr.Markdown(label="–û–ø–∏—Å")

        with gr.Column():
            confidence_output = gr.Label(label="–í–∏–∑–Ω–∞—á–µ–Ω–∏–π —Ñ–æ—Ç–æ—Ç–∏–ø", num_top_classes=3)
            attention_output = gr.Image(label="–ö–∞—Ä—Ç–∞ —Ñ–æ–∫—É—Å—É –º–æ–¥–µ–ª—ñ (XAI)")

    analyze_btn.click(
        fn=predict,
        inputs=image_input,
        outputs=[confidence_output, attention_output, desc_output]
    )

    gr.Markdown(
        """
        ---
        ‚ö† **–ó–∞—Å—Ç–µ—Ä–µ–∂–µ–Ω–Ω—è:**  
        –†–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ —î –º–µ–¥–∏—á–Ω–∏–º –¥—ñ–∞–≥–Ω–æ–∑–æ–º.  
        –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è attention –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –¥–ª—è –ø—ñ–¥–≤–∏—â–µ–Ω–Ω—è —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–æ–≤–∞–Ω–æ—Å—Ç—ñ –º–æ–¥–µ–ª—ñ.
        """
    )

if __name__ == "__main__":
    demo.launch(theme=gr.themes.Soft())